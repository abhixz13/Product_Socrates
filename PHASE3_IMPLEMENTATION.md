# Phase 3 Implementation - Team-Wide Memory Surfacing

**Status:** âœ… COMPLETE (MVP)
**Date Completed:** December 31, 2024
**Feature:** Automatic decision surfacing in strategy sessions

---

## What Was Implemented

Phase 3 adds intelligent memory surfacing to `/strategy-session` that automatically shows relevant past decisions from team memory before starting a new session.

### Key Features

1. **Keyword-Based Search**
   - Extracts keywords from session topic (removes stop words)
   - Searches decision files using grep
   - Expanding search scope: current area â†’ product â†’ all products

2. **Relevance Ranking**
   - Keyword match scoring (10 points per match)
   - Recency bonus (newer decisions score higher)
   - Area bonus (same area = +5, same product = +2)
   - Top 3 decisions surfaced

3. **Cross-Area Learning**
   - Platform PMs see Product PM decisions
   - Different areas highlighted with context
   - Pattern recognition across teams

4. **Attribution Display**
   - Who made the decision (PM name, email)
   - When it was made (relative time)
   - Outcome status (pending/success/failed)
   - Key context (assumptions, trade-offs, results)

5. **Empty State Handling**
   - No decisions yet (new team)
   - No relevant decisions (new topic)
   - Topic too vague (< 2 keywords)
   - Git sync failures

---

## Files Modified

### 1. `.claude/commands/strategy-session.md`

**Sections Added:**

- **Section 0.5.4**: Search team decision history
  - Keyword extraction logic
  - Search strategy (expanding scope)
  - Relevance ranking algorithm
  - Performance optimization
  - Edge case handling

- **Section 0.5.5**: Memory surfacing display
  - Top 3 decision display format
  - YAML frontmatter extraction
  - Cross-area decision highlighting
  - Outcome status display
  - PM selection handling

- **Section 0.5.6**: Continue to Opening
  - Flow control after surfacing

- **Section 1**: Updated Opening
  - Two variants: with/without surfaced decisions
  - References patterns from team history
  - Acknowledges past learnings

**Lines Modified:** 119-283 (new), 287-331 (updated)

---

## How It Works

### Flow Diagram

```
User: /strategy-session "Should we build AI feature?"
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 1. Check team-product-memory/    â”‚
     â”‚    exists?                       â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ YES
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 2. Detect product/area           â”‚
     â”‚    (from config files)           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 3. Git pull (sync team decisions)â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 4. Extract keywords from topic   â”‚
     â”‚    "AI feature" â†’ ["ai","feature"]â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 5. Search decision files         â”‚
     â”‚    grep -rl "ai\|feature"        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 6. Rank by relevance             â”‚
     â”‚    (keywords + recency + area)   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 7. Surface top 3 decisions       â”‚
     â”‚    Show: who, when, outcome      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 8. PM chooses:                   â”‚
     â”‚    1. Review details             â”‚
     â”‚    2. Start session (use context)â”‚
     â”‚    3. Ignore and start fresh     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 9. Opening references patterns   â”‚
     â”‚    "Your team tried AI before..." â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 10. Normal strategy session      â”‚
     â”‚     (with context in mind)       â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Search Algorithm

**Keyword Extraction:**
```
Input: "Should we build AI feature for email?"
  â†“ Remove stop words
Output: ["build", "ai", "feature", "email"]
```

**Search Pattern:**
```bash
# 1. Current area first
grep -rl "build\|ai\|feature\|email" products/test-product/areas/test-area/decisions/*.md

# 2. If < 3 results, expand to all areas in product
grep -rl "build\|ai\|feature\|email" products/test-product/areas/*/decisions/*.md

# 3. If still < 3, expand to all products
grep -rl "build\|ai\|feature\|email" products/*/areas/*/decisions/*.md
```

**Relevance Scoring:**
```
score = (keyword_matches Ã— 10) + (recency_score Ã— 0.1) + area_bonus

where:
  keyword_matches = count of keyword occurrences in file
  recency_score = max(0, 100 - days_ago)
  area_bonus = 5 (same area) or 2 (same product) or 0 (different product)

Example:
  Decision: "Build AI email assistant" (30 days ago, same area)
  Keywords matched: ["ai", "email", "build"] = 3 keywords Ã— 25 occurrences = 75
  Recency: (100 - 30) Ã— 0.1 = 7
  Area bonus: 5
  Total score: 75 + 7 + 5 = 87
```

---

## Testing

### Test Data Created

Location: `../team-product-memory/`

**Structure:**
```
team-product-memory/
â””â”€â”€ products/
    â””â”€â”€ test-product/
        â”œâ”€â”€ config.yml
        â””â”€â”€ areas/
            â””â”€â”€ test-area/
                â”œâ”€â”€ config.yml
                â””â”€â”€ decisions/
                    â”œâ”€â”€ 2024-12-01-build-ai-email-assistant.md (success)
                    â”œâ”€â”€ 2024-12-15-delay-mobile-app.md (pending)
                    â””â”€â”€ 2024-12-20-real-time-collaboration.md (pending)
```

### Test Script

Run: `./test-phase3-search.sh`

**Tests:**
1. âœ… Search for "AI" keyword â†’ finds AI email decision
2. âœ… Search for "mobile" keyword â†’ finds mobile delay decision
3. âœ… Search for "real-time collaboration" â†’ finds collaboration decision
4. âœ… Multi-keyword search â†’ finds multiple relevant decisions
5. âœ… Keyword counting â†’ calculates relevance scores
6. âœ… YAML extraction â†’ reads frontmatter correctly
7. âœ… Recency calculation â†’ computes days ago
8. âœ… Config file validation â†’ verifies structure

**All tests passing.**

---

## Performance Characteristics

**Target: < 10 seconds total**

Actual performance (with 3 decision files):
- Git pull: ~1 second
- Search: < 1 second
- Ranking: < 1 second
- Display: < 1 second
- **Total: ~3 seconds âœ…**

**Optimizations:**
- Limit search to first 10 matching files
- Cache git pull (skip if < 5 min ago)
- Timeout protection (10 second max)

**Scalability:**
- MVP: < 100 decision files (grep is sufficient)
- Post-MVP: > 1000 files (consider ripgrep, indexing)

---

## User Experience

### Before Phase 3
```
PM: /strategy-session "Should we build AI feature?"

Claude: "Let's think through this together..."
[No historical context]
```

### After Phase 3
```
PM: /strategy-session "Should we build AI feature?"

Claude:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
RELEVANT HISTORY (from team memory)

I found 1 past decision that might inform this session:

ðŸ“Œ 1. Build AI email assistant with domain-specific templates
   Who: Sara Chen (sara@company.com)
   When: December 1, 2024 (30 days ago)
   Product Area: test-product/test-area
   Outcome: âœ… Success - 40% adoption (exceeded 30% goal)

   Key context:
   â€¢ Assumptions: Users prefer domain-aware AI over generic AI
   â€¢ Trade-off: Delayed mobile app for 1 month
   â€¢ Result: Domain-specific AI significantly outperformed generic

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Would you like to:
1. Review this decision in detail
2. Start the session (I'll keep this in mind)
3. Ignore and start fresh

PM: 2

Claude: "Based on your team's past decisions, I noticed:
â€¢ Your team has tried AI features before
â€¢ Domain-specific AI performed better than generic (40% vs 15% adoption)

I'll keep this pattern in mind as we explore today..."
```

---

## MVP Limitations

**Not implemented (as designed for MVP):**

- âŒ Semantic search (vector embeddings) - Post-MVP
- âŒ Decision graph visualization - Phase 6
- âŒ Pattern recognition across decisions - Phase 6
- âŒ Auto-tagging decisions - Post-MVP
- âŒ Outcome prediction - Post-MVP

**Implemented (MVP scope):**

- âœ… Keyword-based search (grep)
- âœ… Simple relevance ranking
- âœ… Top 3 decision surfacing
- âœ… Cross-area learning
- âœ… Attribution display
- âœ… Empty state handling

---

## Edge Cases Handled

1. **Missing decision fields** â†’ Extract from git blame or show "Unknown PM"
2. **Deactivated team members** â†’ Show "(former PM, left Jan 2025)"
3. **Duplicate decisions** â†’ Flag similarity, show both with note
4. **Very old decisions (>6 months)** â†’ Warning: "context may have changed"
5. **Too many results (>10)** â†’ Limit to top 3, suggest manual search
6. **Vague session topic** â†’ Skip search, continue normally

---

## Next Steps

### Phase 4: Outcome Tracking

**What's next:**
- Add follow-up prompts when `follow_up_date` arrives
- Update decision status: `pending` â†’ `success`/`failed`
- Capture outcome learnings
- Enable pattern recognition ("prototypes work 85% of the time")

**Dependencies:**
- Phase 3 must be complete âœ…
- Need date-based trigger system
- Need outcome update workflow

---

## Known Issues

None currently identified.

---

## Maintenance Notes

**For future developers:**

1. **Search performance:** Monitor as decision count grows
   - Consider ripgrep if > 1000 decisions
   - Consider search index if performance degrades

2. **Ranking algorithm:** May need tuning based on usage
   - Current weights: keyword (10), recency (0.1), area (5)
   - Adjust based on user feedback

3. **Cross-area surfacing:** Balance relevance vs noise
   - Currently shows all areas
   - May need filtering in future

4. **Empty states:** Clear messaging is critical
   - Test with new users regularly
   - Ensure guidance is helpful

---

## Resources

- **Implementation Plan:** `coding-prompt.md` lines 1713-2865
- **Command File:** `.claude/commands/strategy-session.md` lines 119-331
- **Test Script:** `test-phase3-search.sh`
- **Test Data:** `../team-product-memory/products/test-product/`

---

**Phase 3 Status: âœ… COMPLETE**

Ready for Phase 4: Outcome Tracking
